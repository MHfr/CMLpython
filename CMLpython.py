# -*- coding: utf-8 -*-
"""CMLpython.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13OibJ6pgfhObgnWEZW5iQWU_tjOGEcQC

Training Data
"""

# install packages
# pip install doubleml
# pip install econml

# load data
import doubleml as dml
from doubleml.datasets import fetch_bonus
# load data set on Pennsylvania reemployment bonus experiment
# treatment (tg) is bonus for jobseeker; outcome (inuidur1) is weeks in unemployment
df_bonus = fetch_bonus('DataFrame')
print(df_bonus.head(5))
dml_data_bonus = dml.DoubleMLData(df_bonus,
                                y_col='inuidur1',
                                d_cols='tg',
                                x_cols=['female', 'black', 'othrace', 'dep1', 'dep2',
                                        'q2', 'q3', 'q4', 'q5', 'q6', 'agelt35', 'agegt54',
                                        'durable', 'lusd', 'husd'])

# partialling out based on lasso regression
from sklearn.linear_model import LassoCV
from sklearn.linear_model import LogisticRegressionCV
ml_l = LassoCV()   # outcome model E(Y|X)
ml_m = LogisticRegressionCV(penalty="l1", solver="saga")
est= dml.DoubleMLPLR(dml_data_bonus, ml_l, ml_m) #partialling out
est.fit()   # fit the model
print(est)  # ATE estimate

# partialling out based on the random forest
from sklearn.ensemble import RandomForestRegressor
learner = RandomForestRegressor(max_features = 'sqrt')
ml_l = learner     # outcome model E(Y|X)
ml_m = learner     # treatment model E(D|X)
est=dml.DoubleMLPLR(dml_data_bonus, ml_l, ml_m) #partialling out
est.fit()   # fit the model
print(est)  # ATE estimate

# Causal Forest
from econml.dml import CausalForestDML
from pandas import concat
from sklearn.ensemble import RandomForestClassifier
from pandas import DataFrame
est = CausalForestDML(criterion='het', n_estimators=500,
                      min_samples_leaf=10,
                      max_depth=10, max_samples=0.5,
                      discrete_treatment=True,
                      model_y=RandomForestRegressor(max_features = 'sqrt'),
                      model_t=RandomForestClassifier())
Y=DataFrame(df_bonus.iloc[:, 3])
T=DataFrame(df_bonus.iloc[:, 2])
X=DataFrame(df_bonus.iloc[:, 5:23])
est.fit(Y=Y, T=T, X=X, W=X)
cateX=est.effect(X)
lb, ub = est.effect_interval(X, alpha=0.05) # confidence intervals via bootstrap
cates=concat([DataFrame(cateX),DataFrame(lb),DataFrame(ub)], axis=1)
cates.columns = ['Cates', 'Lower Bound', 'Upper Bound']
print(cates)

# plot histogram of CATEs
import matplotlib.pyplot as plt
plt.hist(cateX, bins=30, edgecolor="black")
plt.xlabel("Estimated CATE")
plt.ylabel("Frequency")
plt.title("Histogram of Estimated CATEs")
plt.show()

# double machine learning based on the random forest
ml_g = learner     # outcome model E(Y|D,X)
ml_m = RandomForestClassifier()     # treatment model E(D|X)
est=dml.DoubleMLIRM(dml_data_bonus, ml_g, ml_m, normalize_ipw=True,
                            trimming_rule='truncate', trimming_threshold=0.01)
est.fit()   # fit the model
print(est)  # ATE estimate

# investigate effect heterogeneity w.r.t. gender and ethnicity
cateX = DataFrame(df_bonus.iloc[:, 5:9])
cates=est.cate(cateX)
cates.fit()    # estimate effect heterogeneity
print(cates)   # evaluate effect heterogeneity

# optimal policy learning
policy_tree=est.policy_tree(features=X, depth=3)
policy_tree.plot_tree();

"""Marketing Data"""

# Double Machine Learning
import pandas as pd                                      # load pandas library
import doubleml as dml                                   # load doubleml library
from sklearn import linear_model                         # load from sklearn
df = pd.read_csv("https://raw.githubusercontent.com/MHfr/CMLpython/main/coupon.csv") # load coupon data
X = df.drop(['dailyspending', 'coupons'], axis = 1)      # define covariates
dml_data = dml.DoubleMLData(df,                          # create data
y_col = 'dailyspending',                                 # define outcome
d_cols = 'coupons',                                      # define intervention
x_cols = list(X.columns.values))                         # define covariates
ml_l = linear_model.LassoCV()                            # learner for outcome
ml_m = linear_model.LogisticRegressionCV(penalty = 'l1', # learner for treatment
solver = 'saga',                                         # solver
max_iter = 350,                                          # max. iterations
Cs = 1,                                                  # inverse regularization
tol = 0.01)                                              # tolerance for stopping
dml_lasso = dml.DoubleMLPLR(dml_data,                    # double machine learning
ml_l,                                                    # outcome model
ml_m,                                                    # treatment model
n_folds = 3).fit()                                       # number of folds
print(dml_lasso.summary)                                 # show the results

# Causal Forest
import pandas as pd                                      # load pandas library
import matplotlib.pyplot as plt                          # load matplotlib library
from econml.dml import CausalForestDML                   # load CausalForest from econml
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier  # load base models

df = pd.read_csv("https://raw.githubusercontent.com/MHfr/CMLpython/main/coupon.csv") # load coupon data
df.columns = df.columns.astype(str)                      # convert column names to strings

Y = df[['dailyspending']]                                # define outcome as DataFrame
D = df[['coupons']]                                      # define treatment as DataFrame
X = df.drop(['dailyspending', 'coupons'], axis=1)        # define covariates

est = CausalForestDML(criterion='het',                   # use criterion for heterogeneity
                      n_estimators=500,                  # number of trees
                      min_samples_leaf=10,               # minimum samples per leaf
                      max_depth=10,                      # maximum tree depth
                      max_samples=0.5,                   # subsample ratio
                      discrete_treatment=True,           # binary treatment
                      model_y=RandomForestRegressor(max_features='sqrt'),  # base model for outcome
                      model_t=RandomForestClassifier())  # base model for treatment

est.fit(Y=Y, T=D, X=X, W=X)                              # fit causal forest

cateX = est.effect(X)                                    # compute CATEs
lb, ub = est.effect_interval(X, alpha=0.05)              # confidence intervals via bootstrap

cates = pd.concat([pd.DataFrame(cateX),                  # combine CATEs
                   pd.DataFrame(lb),                     # lower bounds
                   pd.DataFrame(ub)], axis=1)            # upper bounds
cates.columns = ['CATE', 'Lower Bound', 'Upper Bound']   # rename columns
print(cates)                                             # print CATE table

plt.hist(cateX, color='gray', bins=16, rwidth=0.9)       # plot histogram of CATEs
plt.xlabel('Predictions')                                # set x-axis label
plt.ylabel('Frequency')                                  # set y-axis label
plt.title('Histogram of CATEs')                          # set plot title
plt.show()                                               # show plot

importances = est.feature_importances_        # importances of X in causal forest
importances = importances.ravel() if importances.ndim > 1 else importances
feature_names = X.columns                     # extract names of X
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances                 # use flattened importances
})
print(importance_df)                          # report importances of X

# Double Machine Learning for effect heterogeneity analysis
import pandas as pd                                 # load pandas library
import numpy as np                                  # load numpy library
import doubleml as dml                              # load doubleml library
from sklearn import ensemble                        # load ensemble from sklearn
df = pd.read_csv("https://raw.githubusercontent.com/MHfr/CMLpython/main/coupon.csv") # load coupon data
X = df.drop(['dailyspending', 'coupons'], axis = 1) # select covariates
dml_data = dml.DoubleMLData(df,                     # create data
y_col = 'dailyspending',                            # define outcome
d_cols = 'coupons',                                 # define intervention
x_cols = list(X.columns.values))                    # define covariates
ml_g = ensemble.RandomForestRegressor(max_features = 'sqrt') # outcome model
ml_m = ensemble.RandomForestClassifier()            # intervention model
out = dml.DoubleMLIRM(dml_data,                     # double machine learning
ml_g,                                               # learner for outcome
ml_m,                                               # learner for intervention
normalize_ipw = True,                               # normalize weights
trimming_rule = 'truncate',                         # trimming approach
trimming_threshold = 0.01).fit()                    # threshold for trimming
df['intercept'] = np.ones(len(df))                  # create constant
cateX = df.loc[:, ['intercept', 'dailyspending_preperiod']] # X for heterogeneity
CATEs = out.cate(cateX)                             # estimate effect heterogeneity
print(CATEs)                                        # CATEs by past spending

# Optimal policy tree
policy_tree = out.policy_tree(features = X, depth = 2) # policies for 4 subgroups
policy_tree.plot_tree()                                # tree with optimal policy

"""Private Pension Plan Data"""

# Instrumental variable-based estimation
import pandas as pd                                   # load pandas library
import pandas as pd                                   # load pandas library
from sklearn.linear_model import LogisticRegressionCV # load LogisticRegressionCV
from econml.iv.dr import ForestDRIV                   # load ForestDRIV
import math                                           # load math library
df = pd.read_csv("https://raw.githubusercontent.com/MHfr/CMLpython/main/c401k.csv") # load c401k data
X = df.iloc[:, 4:11]                                  # select covariates
Y = df.iloc[:, 1]                                     # select outcome
W = df.iloc[:, 2]                                     # select treatment
Z = df.iloc[:, 3]                                     # select instrument
ivforest = ForestDRIV(n_estimators = 2000,            # IV forest
                     min_samples_leaf = 5,            # specify min samples leaf
                     max_depth = min(round(math.sqrt(len(X.columns)))+20, len(X.columns)),
                     model_t_xw = LogisticRegressionCV(max_iter = 350),
                     discrete_treatment = True)       # discrete intervention
ivforest.fit(Y = Y, T = W, Z = Z, X = X)              # fit IV forest with data
ATE = ivforest.ate(X)                                 # compute ATE
INF = ivforest.ate_inference(X)                       # compute p-value
print(ATE)                                            # show ATE
print(INF)                                            # show p-value